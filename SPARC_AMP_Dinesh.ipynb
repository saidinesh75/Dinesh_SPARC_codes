{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # BE QUIET!!!! (info and warnings are not printed)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import numpy.linalg as la\n",
    "import numpy.matlib\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "rng = np.random.RandomState(seed=None)\n",
    "import pickle   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "system_params   = {'P': 10.0,   # Average codeword symbol power constraint\n",
    "                 'R': 0.3,      # Rate\n",
    "                 'L': 256,      # Number of sections\n",
    "                 'M': 512,       # Columns per section\n",
    "                 'snr_rx': 31,  # SNR at the receiver  (not in dB)   (SNR of 15 gives a capacity of 2 bits/sec)\n",
    "                 'dist': 1      # 0 for flat and 1 for exponential\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMP Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_dist(power_dist_params):\n",
    "    power_dist_params_list = ['P','L','n','capacity','dist','R']\n",
    "    P,L,n,capacity,dist, R =  map(power_dist_params.get, power_dist_params_list) \n",
    "\n",
    "    #Flat power Distribution\n",
    "    P_vec_flat = P/L * np.ones((L,1))  # Considering Flat power distribution. Can also do exponential distribution\n",
    "\n",
    "    # Exponential Power distribution\n",
    "    P_vec_unnorm = np.zeros(L)\n",
    "    #kappa = 2*capacity\n",
    "    for i in range(L):\n",
    "        P_vec_unnorm[i] = np.power(2, (-2*R*i)/L )\n",
    "    pow_exp = np.sum(P_vec_unnorm)\n",
    "    P_vec_exp = (P/pow_exp) * P_vec_unnorm    # Normalising such that the sum of Pi's = P\n",
    "\n",
    "    if dist==0:\n",
    "        beta_non_zero_values = np.sqrt(n*P_vec_flat)\n",
    "        P_vec = P_vec_flat\n",
    "    else:\n",
    "        beta_non_zero_values = np.sqrt(n*P_vec_exp).reshape((L,1))      #use for exponential power distribution\n",
    "        P_vec = P_vec_exp.reshape((L,1))\n",
    "\n",
    "    return beta_non_zero_values,P_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_message(system_params,rng,cols):\n",
    "    system_params_list = ['P','R','L','M','snr_rx','dist']\n",
    "    P,R,L,M,snr_rx,dist = map(system_params.get, system_params_list) \n",
    "    N = L*M\n",
    "\n",
    "    # Sparse Message vectors with ones (number of msg vectors=cols)\n",
    "    beta = np.zeros((L*M,cols))\n",
    "    beta_val = np.zeros((L*M, cols))\n",
    "\n",
    "    # Same Sparse Message vectors with power allocated non-zero values\n",
    "    beta2 = np.zeros((L*M,cols))\n",
    "    beta2_val = np.zeros((L*M, cols))\n",
    "\n",
    "    #Section sizes \n",
    "    bit_len = int(round(L*np.log2(M)))\n",
    "    logM = int(round(np.log2(M)))\n",
    "    sec_size = logM\n",
    "    L = bit_len // sec_size\n",
    "\n",
    "    # Actual rate\n",
    "    n = int(round(bit_len/R))\n",
    "    R_actual = bit_len / n      \n",
    "\n",
    "    # SNR and noise variance calculation\n",
    "    #snr_rx = np.power(10., snr_rx/10.) * (N/n)              # *log2M (not sure if it should be there)  # according to LISTA code\n",
    "    #snr_rx = P/awgn_var\n",
    "\n",
    "    capacity = 0.5 * np.log2(1 + snr_rx)\n",
    "    \n",
    "    awgn_var = P/snr_rx\n",
    "    sigma = np.sqrt(awgn_var)\n",
    "    \n",
    "    SNR_params = {'snr_rx':snr_rx,\n",
    "                 'awgn_var':awgn_var,\n",
    "                 'capacity':capacity}\n",
    "\n",
    "    # Power allocation\n",
    "    power_dist_params = {'P':P,\n",
    "                        'L':L,\n",
    "                        'n':n,\n",
    "                        'capacity':capacity,\n",
    "                        'dist':dist,        # dist=0 for flat and 1 for exponential\n",
    "                        'R': R_actual\n",
    "                         }\n",
    "    beta_non_zero_values, P_vec = power_dist(power_dist_params)\n",
    "\n",
    "    for i in range(2*cols):\n",
    "        bits_in = rng.randint(2, size=bit_len)\n",
    "        beta0 = np.zeros(L*M)   #placeholder for beta and beta_val (nonzeros =1)\n",
    "        beta1 = np.zeros(L*M)   #placeholder for beta2 and beta2_val (nonzeros = power allocated values)\n",
    "\n",
    "        for l in range(L):\n",
    "            bits_sec = bits_in[l*sec_size : l*sec_size + logM]\n",
    "            assert 0<logM<64\n",
    "            idx = bits_sec.dot(1 << np.arange(logM)[::-1])\n",
    "            beta0[l*M + idx] = 1\n",
    "            beta1[l*M + idx] = beta_non_zero_values[l]\n",
    "\n",
    "        # storing first 'cols' vectors in beta(beta2) and the next 'cols' vectors in beta_val(beta2_val)\n",
    "        if i < cols:\n",
    "            beta[:,i-1] = beta0\n",
    "            beta2[:,i-1] = beta1\n",
    "        else:\n",
    "            beta_val[:,i - cols] = beta0\n",
    "            beta2_val[:, i - cols] = beta1\n",
    "\n",
    "        delim = np.zeros([2,L])\n",
    "        delim[0,0] = 0\n",
    "        delim[1,0] = M-1\n",
    "\n",
    "        for i in range(1,L):\n",
    "            delim[0,i] = delim[1,i-1]+1\n",
    "            delim[1,i] = delim[1,i-1]+M\n",
    "\n",
    "    new_system_params = {'n':n,\n",
    "                        'R_actual': R_actual,\n",
    "                        'delim': delim,\n",
    "                        'P_vec':P_vec\n",
    "                        }\n",
    "                        \n",
    "    return beta, beta2, beta_val, beta2_val, new_system_params,SNR_params, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting all the system parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "system_params_list = ['P','R','L','M','snr_rx']\n",
    "P,R,L,M,snr_rx = map(system_params.get, system_params_list)\n",
    "N = L*M \n",
    "\n",
    "# Generating the message vectors\n",
    "cols = 100\n",
    "beta, beta2, beta_val, beta2_val, new_system_params, SNR_params = generate_message(system_params,rng,cols)\n",
    "\n",
    "# # vectors with 1s\n",
    "# beta = beta.reshape(N,)\n",
    "# beta_val = beta_val.reshape(N,)\n",
    "\n",
    "# # vectors with power allocated values (need to be used for matrix received vector generation)\n",
    "# beta2 = beta.reshape(N,)\n",
    "# beta2_val = beta_val.reshape(N,)\n",
    "\n",
    "# Extracting the new system parameters\n",
    "new_system_params_list = ['n','R_actual','delim','P_vec']\n",
    "n, R, delim,P_vec = map(new_system_params.get, new_system_params_list)\n",
    "\n",
    "# Extracting the SNR params\n",
    "SNR_params_list = ['snr_rx','awgn_var','capacity']\n",
    "snr_rx,awgn_var,capacity = map(SNR_params.get, SNR_params_list)\n",
    "sigma = np.sqrt(awgn_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the A matrix and the received vector (after adding noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(n, N), scale=1.0 / math.sqrt(n)).astype(np.float32)\n",
    "#A = A_unn/np.linalg.norm(A_unn,axis=0) \n",
    "y = np.matmul(A,beta2) + np.random.normal( size = (n,cols), scale = math.sqrt(awgn_var) )\n",
    "\n",
    "# need to check how to get ||Ax||^2 = ||x||^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMP Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta(beta_hat, P_vec, tau, delim):\n",
    "    beta_th = np.zeros(np.shape(beta_hat))\n",
    "    rows,cols = beta_hat.shape \n",
    "    L = np.size(P_vec)\n",
    "    M = rows/L\n",
    "\n",
    "    for i in range(cols):\n",
    "        s1 = beta_hat[:,i]\n",
    "        for j in range(L):\n",
    "            beta_section = s1[ int(delim[0,j]):int(delim[1,j]+1)]\n",
    "            beta_th_section = np.zeros(int(M))\n",
    "            denom = np.sum( np.exp( (beta_section* np.sqrt(n*P_vec[j]))/(tau**2) ) )\n",
    "            for k in range(int(M)):\n",
    "                num = np.exp( (beta_section[k]* np.sqrt(n*P_vec[j]))/(tau**2) )\n",
    "                beta_th_section[k] = num/denom\n",
    "            beta_th[int(delim[0,j]):int(delim[1,j]+1), i] = beta_th_section\n",
    "\n",
    "    return beta_th        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_calculate(sigma_sq,delim, P, P_vec, T_star, n):\n",
    "    tau_vec = np.zeros([T_star,1])\n",
    "    x = np.zeros([T_star,1])\n",
    "    tau_vec[0] = sigma_sq + P\n",
    "    ITR = 10^4\n",
    "\n",
    "    for t in range(1,T_star):\n",
    "        exp_vec = np.zeros([np.size(P_vec),1])\n",
    "\n",
    "        for i in range(ITR):\n",
    "            U = rng.randn(int(delim[-1,-1]))\n",
    "            for l in range(np.size(P_vec)):\n",
    "                # Numerator\n",
    "                num_1 =  np.sqrt(n*P_vec[l],dtype=np.float128)/tau_vec[t-1]\n",
    "                num_21 = U[int(delim[0,l])]\n",
    "                num = np.exp( num_1 * (num_1 + num_21 ),dtype=np.float128)\n",
    "\n",
    "                # Denominator\n",
    "                denom_21 = U[ int(delim[0,l]+1) : int(delim[1,l]+1) ]\n",
    "                denom_2 = np.sum( np.exp( np.multiply(num_1,denom_21) ), dtype=np.float128)\n",
    "                denom = num + denom_2\n",
    "\n",
    "                exp_vec[l] = exp_vec[l] + np.divide(num,denom, dtype=np.float128)\n",
    "\n",
    "        exp_vec = np.divide(exp_vec,ITR)\n",
    "        x1 = np.ndarray.item(np.float128(np.matmul(P_vec.T,exp_vec)/P)) # getting saved as an (1,1) ndarray\n",
    "        \n",
    "        tau_vec[t] = sigma_sq + P*(1-x1)\n",
    "        x[t] = x1\n",
    "\n",
    "    return tau_vec, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_arr = beta[:,0]\n",
    "# nonzero_beta = np.nonzero(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_star = int(np.ceil((2*capacity)/np.log2(capacity/R)) + 1)\n",
    "tau_vec1, x= tau_calculate(awgn_var, delim,P,P_vec,T_star,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_vec = np.concatenate((tau_vec1[0].reshape([1,1]),tau_vec1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "beta_T = np.zeros((N,cols))\n",
    "beta_hat = np.zeros((N,cols))\n",
    "z = np.zeros((n,cols))\n",
    "\n",
    "\n",
    "# beta_hat_nz_cdf = np.zeros( [int(np.size(nonzero_beta)),T_star] )\n",
    "\n",
    "for t in range(T_star):\n",
    "    z = y - np.matmul(A, beta_hat) + (z/tau_vec[t])*(P - (np.linalg.norm(beta_hat)**2)/n )\n",
    "    beta_hat = beta_hat + np.matmul(A.T,z)\n",
    "    beta_hat = eta(beta_hat,P_vec, tau_vec[t],delim)\n",
    "    \n",
    "    # beta_hat_test = beta_hat[nonzero_beta,0].reshape([-1,1])\n",
    "    # beta_hat_nz_cdf[:,t] = np.divide(beta_hat_test,np.sqrt(n*P_vec)).reshape([L,])\n",
    "    \n",
    "    \n",
    "for j in range(L):\n",
    "    loc = np.argmax( beta_hat[ int(delim[0,j]) : int(delim[1,j]) ], axis=0 )\n",
    "    for k in range(np.size(loc)):\n",
    "        beta_T[ int(delim[0,j]) + loc[k],k ] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29\n"
     ]
    }
   ],
   "source": [
    "check = beta-beta_T\n",
    "check_sum = np.sum(np.absolute(check),axis=0)/2\n",
    "check_avg = np.average(check_sum)\n",
    "print(check_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_params = system_params.copy()\n",
    "# output_params['check_avg']=check_avg\n",
    "\n",
    "# filename = 'Avg_ction_error_rate_output'\n",
    "\n",
    "# infile = open(filename,'rb')\n",
    "# out_list = pickle.load(infile)\n",
    "\n",
    "# out_list.append(system_params)\n",
    "\n",
    "# # outfile = open(filename,'wb')\n",
    "# with open(filename,'wb') as outfile:\n",
    "#     pickle.dump(out_list,outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow-test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27581de6d80e5a5a3bac653d6793b7dc8a23f16ccb931cd5e47c2ad8a3cf817b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
